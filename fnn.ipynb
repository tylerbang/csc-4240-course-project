{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "# import the usual libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.utils import to_categorical\n",
    "# from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# other machine learning modules\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# commonly used modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attendance = pd.read_csv('attendance.csv')\n",
    "df_games = pd.read_csv('games.csv')\n",
    "\n",
    "excludeYears = [2000, 2001]\n",
    "\n",
    "# Removes any rows containing a null value from the datasets\n",
    "df_attendance = df_attendance[~df_attendance['year'].isin(excludeYears)]\n",
    "df_attendance = df_attendance.dropna()\n",
    "droppit = ['team', 'total', 'home', 'away']\n",
    "df_attendance = df_attendance.drop(droppit, axis=1)\n",
    "df_attendance.rename(columns={'team_name': 'home_team_name'}, inplace=True)\n",
    "df_attendance['week'] = df_attendance['week'].astype(int)\n",
    "\n",
    "df_games = df_games[~df_games['year'].isin(excludeYears)]\n",
    "droppa = ['home_team', 'away_team', 'tie', 'home_team_city', 'away_team_city']\n",
    "exclude_weeks = ['WildCard', 'Division', 'ConfChamp', 'SuperBowl']\n",
    "df_games = df_games.drop(droppa, axis=1)\n",
    "df_games = df_games[~df_games['week'].isin(exclude_weeks)]\n",
    "df_games = df_games.dropna()\n",
    "df_games['week'] = df_games['week'].astype(int)\n",
    "\n",
    "right = ['year', 'week', 'home_team_name']\n",
    "df_result = df_attendance.merge(df_games, on=right)\n",
    "to_convert_categorical = ['home_team_name', 'time', 'winner', 'day', 'away_team_name']\n",
    "\n",
    "df_result[to_convert_categorical] = df_result[to_convert_categorical].astype('category')\n",
    "df_result = df_result.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Data team will handle putting in the training, validation, and test data\n",
    "X = df_attendance.drop('weekly_attendance', axis=1)\n",
    "Y = df_attendance['weekly_attendance']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) # TODO: need training data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', activation='relu', neurons=64):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=X_train.shape[1], activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'neurons': [32, 64, 128]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scorer, cv=5)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_result.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "print(\"Final Mean Squared Error on Test Set:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
